{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "15-pSeFpYUYe4kvUX4Zr8KpXwono8HCs3",
      "authorship_tag": "ABX9TyPZavReLfvHrGoIN749wfm3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FaizaAbbasi988/ShallowNet-on-EEG-Data/blob/main/ShallowNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFrR9zIGmCF2",
        "outputId": "edfabc4e-4327-4c6b-f7e8-660179083821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n"
          ]
        }
      ],
      "source": [
        "pip install einops #to simplify and streamline the manipulation of tensor shapes and dimensions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import math\n",
        "import glob\n",
        "import random\n",
        "import itertools\n",
        "import datetime\n",
        "import time\n",
        "import sys\n",
        "import scipy.io\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image, make_grid\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "from torchsummary import summary\n",
        "import torch.autograd as autograd\n",
        "from torchvision.models import vgg19\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torch.nn.init as init\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "from PIL import Image\n",
        "from torchvision.transforms import Compose, Resize, ToTensor\n",
        "from einops import rearrange, reduce, repeat\n",
        "from einops.layers.torch import Rearrange, Reduce\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.backends import cudnn\n",
        "cudnn.benchmark = False\n",
        "cudnn.deterministic = True\n",
        "writer = SummaryWriter('./TensorBoardX/')"
      ],
      "metadata": {
        "id": "zDnDgn4mXjIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convolution module\n",
        "class CNNmod(nn.Module):\n",
        "    def __init__(self):\n",
        "        # self.patch_size = patch_size\n",
        "        super().__init__()\n",
        "\n",
        "        self.shallownet = nn.Sequential(\n",
        "            nn.Conv2d(1, 40, (1, 25), (1, 1)),\n",
        "            nn.Conv2d(40, 40, (22, 1), (1, 1)),\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d((1, 75), (1, 15)),\n",
        "            nn.Dropout(0.5),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.shallownet(x)\n",
        "        return x\n",
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self,  n_classes):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(2440, 256),\n",
        "            nn.ELU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 32),\n",
        "            nn.ELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(32, 4)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.contiguous().view(x.size(0), -1)\n",
        "        out = self.fc(x)\n",
        "        return x, out\n",
        "class CNN(nn.Sequential):\n",
        "    def __init__(self, n_classes=4, **kwargs):\n",
        "        super().__init__(\n",
        "            CNNmod(),\n",
        "            ClassificationHead(n_classes),\n",
        "        )"
      ],
      "metadata": {
        "id": "ZjNuh_n_Xn2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = '/content/drive/MyDrive/sortedData/BCIcompIV-2a/sorted2'\n",
        "\n",
        "# Load training data\n",
        "total_data = scipy.io.loadmat(root + 'T.mat')\n",
        "train_data = total_data['data']\n",
        "train_label = total_data['label']\n",
        "\n",
        "# Transpose and expand dimensions\n",
        "train_data = np.transpose(train_data, (2, 1, 0))\n",
        "train_data = np.expand_dims(train_data, axis=1)\n",
        "train_label = np.transpose(train_label)\n",
        "\n",
        "# Shuffle the data\n",
        "shuffle_num = np.random.permutation(len(train_data))\n",
        "train_data = train_data[shuffle_num, :, :, :]\n",
        "train_label = train_label[:, shuffle_num]\n",
        "\n",
        "# Load test data\n",
        "test_tmp = scipy.io.loadmat(root + 'E.mat')\n",
        "test_data = test_tmp['data']\n",
        "test_label = test_tmp['label']\n",
        "\n",
        "# Transpose and expand dimensions\n",
        "test_data = np.transpose(test_data, (2, 1, 0))\n",
        "test_data = np.expand_dims(test_data, axis=1)\n",
        "test_label = np.transpose(test_label)\n",
        "\n",
        "# Standardize data\n",
        "target_mean = np.mean(train_data)\n",
        "target_std = np.std(train_data)\n",
        "train_data = (train_data - target_mean) / target_std\n",
        "test_data = (test_data - target_mean) / target_std\n",
        "\n",
        "print(\"The shape of training data is\", train_data.shape)\n",
        "print(\"The shape of test data is\", test_data.shape)\n",
        "print(\"The shape of train label is\", train_label.shape)\n",
        "print(\"The shape of test label is\", test_label.shape)\n",
        "test_label= test_label-1\n",
        "test_label\n",
        "train_label= train_label-1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rjf9-Og1Xvlb",
        "outputId": "e4e871ab-b7a3-416c-8afb-aeac771cd4ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of training data is (288, 1, 22, 1000)\n",
            "The shape of test data is (288, 1, 22, 1000)\n",
            "The shape of train label is (1, 288)\n",
            "The shape of test label is (1, 288)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ExP():\n",
        "    def __init__(self, nsub):\n",
        "        super(ExP, self).__init__()\n",
        "        self.batch_size = 72\n",
        "        self.n_epochs = 2\n",
        "        # self.c_dim = 4\n",
        "        self.lr = 0.001\n",
        "        self.b1 = 0.5\n",
        "        self.b2 = 0.999\n",
        "        self.nSub = nsub\n",
        "\n",
        "        self.start_epoch = 0\n",
        "        self.Tensor = torch.FloatTensor\n",
        "        self.LongTensor = torch.LongTensor\n",
        "\n",
        "        self.criterion_l1 = torch.nn.L1Loss()\n",
        "        self.criterion_l2 = torch.nn.MSELoss()\n",
        "        self.criterion_cls = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "        self.model = CNN()\n",
        "\n",
        "    def get_source_data(self):\n",
        "        self.allData = train_data\n",
        "        self.allLabel = train_label[0]\n",
        "        self.testData = test_data\n",
        "        self.testLabel = test_label[0]\n",
        "        return self.allData, self.allLabel, self.testData, self.testLabel\n",
        "\n",
        "    def train(self):\n",
        "\n",
        "        img, label, test_data, test_label = self.get_source_data()\n",
        "\n",
        "        img = torch.from_numpy(img)\n",
        "        label = torch.from_numpy(label)\n",
        "        dataset = torch.utils.data.TensorDataset(img, label)\n",
        "        self.dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "        test_data = torch.from_numpy(test_data)\n",
        "        test_label = torch.from_numpy(test_label)\n",
        "        test_dataset = torch.utils.data.TensorDataset(test_data, test_label)\n",
        "        self.test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "        # Optimizers\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, betas=(self.b1, self.b2))\n",
        "\n",
        "        test_data = Variable(test_data.type(self.Tensor))\n",
        "        test_label = Variable(test_label.type(self.LongTensor))\n",
        "\n",
        "        bestAcc = 0\n",
        "        averAcc = 0\n",
        "        num = 0\n",
        "        Y_true = 0\n",
        "        Y_pred = 0\n",
        "\n",
        "        # Train the cnn model\n",
        "        total_step = len(self.dataloader)\n",
        "        curr_lr = self.lr\n",
        "\n",
        "        for e in range(self.n_epochs):\n",
        "            # in_epoch = time.time()\n",
        "            self.model.train()\n",
        "            for i, (img, label) in enumerate(self.dataloader):\n",
        "\n",
        "                img = Variable(img.type(self.Tensor))\n",
        "                label = Variable(label.type(self.LongTensor))\n",
        "                tok, outputs = self.model(img)\n",
        "\n",
        "                loss = self.criterion_cls(outputs, label)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "\n",
        "            # out_epoch = time.time()\n",
        "\n",
        "\n",
        "            # test process\n",
        "            if (e + 1) % 1 == 0:\n",
        "                self.model.eval()\n",
        "                Tok, Cls = self.model(test_data)\n",
        "\n",
        "\n",
        "                loss_test = self.criterion_cls(Cls, test_label)\n",
        "                y_pred = torch.max(Cls, 1)[1]\n",
        "                # print(\"cls\", Cls)\n",
        "                # print(\"y_pred\", y_pred)\n",
        "                acc = float((y_pred == test_label).cpu().numpy().astype(int).sum()) / float(test_label.size(0))\n",
        "                train_pred = torch.max(outputs, 1)[1]\n",
        "                train_acc = float((train_pred == label).cpu().numpy().astype(int).sum()) / float(label.size(0))\n",
        "\n",
        "                print('Epoch:', e,\n",
        "                      '  Train loss: %.6f' % loss.detach().cpu().numpy(),\n",
        "                      '  Test loss: %.6f' % loss_test.detach().cpu().numpy(),\n",
        "                      '  Train accuracy %.6f' % train_acc,\n",
        "                      '  Test accuracy is %.6f' % acc)\n",
        "\n",
        "\n",
        "                num = num + 1\n",
        "                averAcc = averAcc + acc\n",
        "                if acc > bestAcc:\n",
        "                    bestAcc = acc\n",
        "                    Y_true = test_label\n",
        "                    Y_pred = y_pred\n",
        "\n",
        "        averAcc = averAcc / num\n",
        "        print('The average accuracy is:', averAcc)\n",
        "        print('The best accuracy is:', bestAcc)\n",
        "\n",
        "        return bestAcc, averAcc, Y_true, Y_pred\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    best = 0\n",
        "    aver = 0\n",
        "\n",
        "\n",
        "    for i in range(1):\n",
        "        starttime = datetime.datetime.now()\n",
        "\n",
        "\n",
        "        seed_n = np.random.randint(2021)\n",
        "        print('seed is ' + str(seed_n))\n",
        "        random.seed(seed_n)\n",
        "        np.random.seed(seed_n)\n",
        "        torch.manual_seed(seed_n)\n",
        "        torch.manual_seed(seed_n)\n",
        "        torch.cuda.manual_seed_all(seed_n)\n",
        "\n",
        "\n",
        "        print('Subject %d' % (i+1))\n",
        "        exp = ExP(i + 1)\n",
        "\n",
        "        bestAcc, averAcc, Y_true, Y_pred = exp.train()\n",
        "        endtime = datetime.datetime.now()\n",
        "        print('subject %d duration: '%(i+1) + str(endtime - starttime))\n",
        "        best = best + bestAcc\n",
        "        aver = aver + averAcc\n",
        "        if i == 0:\n",
        "            yt = Y_true\n",
        "            yp = Y_pred\n",
        "        else:\n",
        "            yt = torch.cat((yt, Y_true))\n",
        "            yp = torch.cat((yp, Y_pred))\n",
        "\n",
        "\n",
        "    best = best / 9\n",
        "    aver = aver / 9\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(time.asctime(time.localtime(time.time())))\n",
        "    main()\n",
        "    print(time.asctime(time.localtime(time.time())))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYUonHYjX-Wx",
        "outputId": "96cf0bac-3565-4b7c-9af5-89d6e9656012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Apr 19 09:55:08 2024\n",
            "seed is 1683\n",
            "Subject 1\n",
            "Epoch: 0   Train loss: 1.393567   Test loss: 1.397448   Train accuracy 0.263889   Test accuracy is 0.256944\n",
            "Epoch: 1   Train loss: 1.349799   Test loss: 1.387040   Train accuracy 0.319444   Test accuracy is 0.281250\n",
            "The average accuracy is: 0.2690972222222222\n",
            "The best accuracy is: 0.28125\n",
            "THE BEST ACCURACY IS 0.28125\n",
            "subject 1 duration: 0:00:23.567949\n",
            "Fri Apr 19 09:55:32 2024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_VYAdLB9YS0l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}