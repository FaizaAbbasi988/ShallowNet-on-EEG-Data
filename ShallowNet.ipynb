{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "15-pSeFpYUYe4kvUX4Zr8KpXwono8HCs3",
      "authorship_tag": "ABX9TyM0nS6EMyQPgS+TtstiL1d3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FaizaAbbasi988/ShallowNet-on-EEG-Data/blob/main/ShallowNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFrR9zIGmCF2",
        "outputId": "edfabc4e-4327-4c6b-f7e8-660179083821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n"
          ]
        }
      ],
      "source": [
        "pip install einops #to simplify and streamline the manipulation of tensor shapes and dimensions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import math\n",
        "import glob\n",
        "import random\n",
        "import itertools\n",
        "import datetime\n",
        "import time\n",
        "import sys\n",
        "import scipy.io\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image, make_grid\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "from torchsummary import summary\n",
        "import torch.autograd as autograd\n",
        "from torchvision.models import vgg19\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torch.nn.init as init\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "from PIL import Image\n",
        "from torchvision.transforms import Compose, Resize, ToTensor\n",
        "from einops import rearrange, reduce, repeat\n",
        "from einops.layers.torch import Rearrange, Reduce\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.backends import cudnn\n",
        "cudnn.benchmark = False\n",
        "cudnn.deterministic = True\n",
        "writer = SummaryWriter('./TensorBoardX/')"
      ],
      "metadata": {
        "id": "zDnDgn4mXjIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convolution module\n",
        "class CNNmod(nn.Module):\n",
        "    def __init__(self):\n",
        "        # self.patch_size = patch_size\n",
        "        super().__init__()\n",
        "\n",
        "        self.shallownet = nn.Sequential(\n",
        "            nn.Conv2d(1, 40, (1, 25), (1, 1)),\n",
        "            nn.Conv2d(40, 40, (22, 1), (1, 1)),\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d((1, 75), (1, 15)),\n",
        "            nn.Dropout(0.5),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.shallownet(x)\n",
        "        return x\n",
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self,  n_classes):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(2440, 256),\n",
        "            nn.ELU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 32),\n",
        "            nn.ELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(32, 4)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.contiguous().view(x.size(0), -1)\n",
        "        out = self.fc(x)\n",
        "        return x, out\n",
        "class CNN(nn.Sequential):\n",
        "    def __init__(self, n_classes=4, **kwargs):\n",
        "        super().__init__(\n",
        "            CNNmod(),\n",
        "            ClassificationHead(n_classes),\n",
        "        )"
      ],
      "metadata": {
        "id": "ZjNuh_n_Xn2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eAtATP0-3OiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = '/content/drive/MyDrive/sortedData/BCIcompIV-2a/sorted1'\n",
        "\n",
        "# Load training data\n",
        "total_data = scipy.io.loadmat(root + 'T.mat')\n",
        "train_data = total_data['data']\n",
        "train_label = total_data['label']\n",
        "\n",
        "# Transpose and expand dimensions\n",
        "train_data = np.transpose(train_data, (2, 1, 0))\n",
        "train_data = np.expand_dims(train_data, axis=1)\n",
        "train_label = np.transpose(train_label)\n",
        "\n",
        "# Shuffle the data\n",
        "shuffle_num = np.random.permutation(len(train_data))\n",
        "train_data = train_data[shuffle_num, :, :, :]\n",
        "train_label = train_label[:, shuffle_num]\n",
        "\n",
        "# Load test data\n",
        "test_tmp = scipy.io.loadmat(root + 'E.mat')\n",
        "test_data = test_tmp['data']\n",
        "test_label = test_tmp['label']\n",
        "\n",
        "# Transpose and expand dimensions\n",
        "test_data = np.transpose(test_data, (2, 1, 0))\n",
        "test_data = np.expand_dims(test_data, axis=1)\n",
        "test_label = np.transpose(test_label)\n",
        "\n",
        "# Standardize data\n",
        "target_mean = np.mean(train_data)\n",
        "target_std = np.std(train_data)\n",
        "train_data = (train_data - target_mean) / target_std\n",
        "test_data = (test_data - target_mean) / target_std\n",
        "\n",
        "print(\"The shape of training data is\", train_data.shape)\n",
        "print(\"The shape of test data is\", test_data.shape)\n",
        "print(\"The shape of train label is\", train_label.shape)\n",
        "print(\"The shape of test label is\", test_label.shape)\n",
        "test_label= test_label-1\n",
        "test_label\n",
        "train_label= train_label-1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rjf9-Og1Xvlb",
        "outputId": "ec2deaf7-c3d4-4f48-fc7f-f4d882c14b77"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of training data is (288, 1, 22, 1000)\n",
            "The shape of test data is (288, 1, 22, 1000)\n",
            "The shape of train label is (1, 288)\n",
            "The shape of test label is (1, 288)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ExP():\n",
        "    def __init__(self, nsub):\n",
        "        super(ExP, self).__init__()\n",
        "        self.batch_size = 72\n",
        "        self.n_epochs = 50\n",
        "        # self.c_dim = 4\n",
        "        self.lr = 0.001\n",
        "        self.b1 = 0.5\n",
        "        self.b2 = 0.999\n",
        "        self.nSub = nsub\n",
        "\n",
        "        self.start_epoch = 0\n",
        "        self.Tensor = torch.FloatTensor\n",
        "        self.LongTensor = torch.LongTensor\n",
        "\n",
        "        self.criterion_l1 = torch.nn.L1Loss()\n",
        "        self.criterion_l2 = torch.nn.MSELoss()\n",
        "        self.criterion_cls = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "        self.model = CNN()\n",
        "\n",
        "    def get_source_data(self):\n",
        "        self.allData = train_data\n",
        "        self.allLabel = train_label[0]\n",
        "        self.testData = test_data\n",
        "        self.testLabel = test_label[0]\n",
        "        return self.allData, self.allLabel, self.testData, self.testLabel\n",
        "\n",
        "    def train(self):\n",
        "\n",
        "        img, label, test_data, test_label = self.get_source_data()\n",
        "\n",
        "        img = torch.from_numpy(img)\n",
        "        label = torch.from_numpy(label)\n",
        "        dataset = torch.utils.data.TensorDataset(img, label)\n",
        "        self.dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "        test_data = torch.from_numpy(test_data)\n",
        "        test_label = torch.from_numpy(test_label)\n",
        "        test_dataset = torch.utils.data.TensorDataset(test_data, test_label)\n",
        "        self.test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "        # Optimizers\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, betas=(self.b1, self.b2))\n",
        "\n",
        "        test_data = Variable(test_data.type(self.Tensor))\n",
        "        test_label = Variable(test_label.type(self.LongTensor))\n",
        "\n",
        "        bestAcc = 0\n",
        "        averAcc = 0\n",
        "        num = 0\n",
        "        Y_true = 0\n",
        "        Y_pred = 0\n",
        "\n",
        "        # Train the cnn model\n",
        "        total_step = len(self.dataloader)\n",
        "        curr_lr = self.lr\n",
        "\n",
        "        for e in range(self.n_epochs):\n",
        "            # in_epoch = time.time()\n",
        "            self.model.train()\n",
        "            for i, (img, label) in enumerate(self.dataloader):\n",
        "\n",
        "                img = Variable(img.type(self.Tensor))\n",
        "                label = Variable(label.type(self.LongTensor))\n",
        "                tok, outputs = self.model(img)\n",
        "\n",
        "                loss = self.criterion_cls(outputs, label)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "\n",
        "            # out_epoch = time.time()\n",
        "\n",
        "\n",
        "            # test process\n",
        "            if (e + 1) % 1 == 0:\n",
        "                self.model.eval()\n",
        "                Tok, Cls = self.model(test_data)\n",
        "\n",
        "\n",
        "                loss_test = self.criterion_cls(Cls, test_label)\n",
        "                y_pred = torch.max(Cls, 1)[1]\n",
        "                # print(\"cls\", Cls)\n",
        "                # print(\"y_pred\", y_pred)\n",
        "                acc = float((y_pred == test_label).cpu().numpy().astype(int).sum()) / float(test_label.size(0))\n",
        "                train_pred = torch.max(outputs, 1)[1]\n",
        "                train_acc = float((train_pred == label).cpu().numpy().astype(int).sum()) / float(label.size(0))\n",
        "\n",
        "                print('Epoch:', e,\n",
        "                      '  Train loss: %.6f' % loss.detach().cpu().numpy(),\n",
        "                      '  Test loss: %.6f' % loss_test.detach().cpu().numpy(),\n",
        "                      '  Train accuracy %.6f' % train_acc,\n",
        "                      '  Test accuracy is %.6f' % acc)\n",
        "\n",
        "\n",
        "                num = num + 1\n",
        "                averAcc = averAcc + acc\n",
        "                if acc > bestAcc:\n",
        "                    bestAcc = acc\n",
        "                    Y_true = test_label\n",
        "                    Y_pred = y_pred\n",
        "\n",
        "        averAcc = averAcc / num\n",
        "        print('The average accuracy is:', averAcc)\n",
        "        print('The best accuracy is:', bestAcc)\n",
        "\n",
        "        return bestAcc, averAcc, Y_true, Y_pred\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    best = 0\n",
        "    aver = 0\n",
        "\n",
        "\n",
        "    for i in range(1):\n",
        "        starttime = datetime.datetime.now()\n",
        "\n",
        "\n",
        "        seed_n = np.random.randint(2021)\n",
        "        print('seed is ' + str(seed_n))\n",
        "        random.seed(seed_n)\n",
        "        np.random.seed(seed_n)\n",
        "        torch.manual_seed(seed_n)\n",
        "        torch.manual_seed(seed_n)\n",
        "        torch.cuda.manual_seed_all(seed_n)\n",
        "\n",
        "\n",
        "        print('Subject %d' % (i+1))\n",
        "        exp = ExP(i + 1)\n",
        "\n",
        "        bestAcc, averAcc, Y_true, Y_pred = exp.train()\n",
        "        endtime = datetime.datetime.now()\n",
        "        print('subject %d duration: '%(i+1) + str(endtime - starttime))\n",
        "        best = best + bestAcc\n",
        "        aver = aver + averAcc\n",
        "        if i == 0:\n",
        "            yt = Y_true\n",
        "            yp = Y_pred\n",
        "        else:\n",
        "            yt = torch.cat((yt, Y_true))\n",
        "            yp = torch.cat((yp, Y_pred))\n",
        "\n",
        "\n",
        "    best = best / 9\n",
        "    aver = aver / 9\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(time.asctime(time.localtime(time.time())))\n",
        "    main()\n",
        "    print(time.asctime(time.localtime(time.time())))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYUonHYjX-Wx",
        "outputId": "6377452c-b53d-4bf6-abb5-b9a70f2750ec"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Apr 19 10:19:44 2024\n",
            "seed is 957\n",
            "Subject 1\n",
            "Epoch: 0   Train loss: 1.369003   Test loss: 1.384547   Train accuracy 0.305556   Test accuracy is 0.256944\n",
            "Epoch: 1   Train loss: 1.361542   Test loss: 1.372963   Train accuracy 0.375000   Test accuracy is 0.250000\n",
            "Epoch: 2   Train loss: 1.306024   Test loss: 1.310905   Train accuracy 0.361111   Test accuracy is 0.434028\n",
            "Epoch: 3   Train loss: 1.125802   Test loss: 1.193589   Train accuracy 0.597222   Test accuracy is 0.493056\n",
            "Epoch: 4   Train loss: 0.995929   Test loss: 1.028757   Train accuracy 0.500000   Test accuracy is 0.538194\n",
            "Epoch: 5   Train loss: 0.862747   Test loss: 0.992401   Train accuracy 0.652778   Test accuracy is 0.496528\n",
            "Epoch: 6   Train loss: 0.836226   Test loss: 0.939033   Train accuracy 0.611111   Test accuracy is 0.513889\n",
            "Epoch: 7   Train loss: 0.827666   Test loss: 0.838037   Train accuracy 0.722222   Test accuracy is 0.618056\n",
            "Epoch: 8   Train loss: 0.799070   Test loss: 0.940757   Train accuracy 0.625000   Test accuracy is 0.559028\n",
            "Epoch: 9   Train loss: 0.722588   Test loss: 0.808144   Train accuracy 0.722222   Test accuracy is 0.625000\n",
            "Epoch: 10   Train loss: 0.633700   Test loss: 0.755367   Train accuracy 0.791667   Test accuracy is 0.652778\n",
            "Epoch: 11   Train loss: 0.645969   Test loss: 0.803044   Train accuracy 0.722222   Test accuracy is 0.625000\n",
            "Epoch: 12   Train loss: 0.506043   Test loss: 0.874515   Train accuracy 0.763889   Test accuracy is 0.611111\n",
            "Epoch: 13   Train loss: 0.649231   Test loss: 0.745376   Train accuracy 0.694444   Test accuracy is 0.670139\n",
            "Epoch: 14   Train loss: 0.518602   Test loss: 1.165525   Train accuracy 0.750000   Test accuracy is 0.503472\n",
            "Epoch: 15   Train loss: 0.468988   Test loss: 0.705184   Train accuracy 0.777778   Test accuracy is 0.659722\n",
            "Epoch: 16   Train loss: 0.401616   Test loss: 0.722272   Train accuracy 0.847222   Test accuracy is 0.666667\n",
            "Epoch: 17   Train loss: 0.425401   Test loss: 0.692548   Train accuracy 0.819444   Test accuracy is 0.680556\n",
            "Epoch: 18   Train loss: 0.507447   Test loss: 0.904702   Train accuracy 0.750000   Test accuracy is 0.614583\n",
            "Epoch: 19   Train loss: 0.418725   Test loss: 0.859539   Train accuracy 0.763889   Test accuracy is 0.670139\n",
            "Epoch: 20   Train loss: 0.272844   Test loss: 0.778445   Train accuracy 0.875000   Test accuracy is 0.631944\n",
            "Epoch: 21   Train loss: 0.361126   Test loss: 0.687455   Train accuracy 0.861111   Test accuracy is 0.711806\n",
            "Epoch: 22   Train loss: 0.381395   Test loss: 0.683166   Train accuracy 0.833333   Test accuracy is 0.701389\n",
            "Epoch: 23   Train loss: 0.220909   Test loss: 0.696828   Train accuracy 0.944444   Test accuracy is 0.704861\n",
            "Epoch: 24   Train loss: 0.269287   Test loss: 0.725142   Train accuracy 0.916667   Test accuracy is 0.684028\n",
            "Epoch: 25   Train loss: 0.157898   Test loss: 0.836963   Train accuracy 0.972222   Test accuracy is 0.670139\n",
            "Epoch: 26   Train loss: 0.279079   Test loss: 0.835403   Train accuracy 0.902778   Test accuracy is 0.666667\n",
            "Epoch: 27   Train loss: 0.268819   Test loss: 0.678496   Train accuracy 0.888889   Test accuracy is 0.718750\n",
            "Epoch: 28   Train loss: 0.202932   Test loss: 0.921570   Train accuracy 0.930556   Test accuracy is 0.625000\n",
            "Epoch: 29   Train loss: 0.254087   Test loss: 1.326252   Train accuracy 0.888889   Test accuracy is 0.597222\n",
            "Epoch: 30   Train loss: 0.339166   Test loss: 0.835804   Train accuracy 0.861111   Test accuracy is 0.652778\n",
            "Epoch: 31   Train loss: 0.159818   Test loss: 0.825046   Train accuracy 0.958333   Test accuracy is 0.718750\n",
            "Epoch: 32   Train loss: 0.300121   Test loss: 0.847948   Train accuracy 0.888889   Test accuracy is 0.652778\n",
            "Epoch: 33   Train loss: 0.179810   Test loss: 0.835722   Train accuracy 0.944444   Test accuracy is 0.701389\n",
            "Epoch: 34   Train loss: 0.150903   Test loss: 0.733597   Train accuracy 0.972222   Test accuracy is 0.718750\n",
            "Epoch: 35   Train loss: 0.155059   Test loss: 0.790354   Train accuracy 0.958333   Test accuracy is 0.677083\n",
            "Epoch: 36   Train loss: 0.193193   Test loss: 0.965695   Train accuracy 0.902778   Test accuracy is 0.652778\n",
            "Epoch: 37   Train loss: 0.130439   Test loss: 0.756138   Train accuracy 0.972222   Test accuracy is 0.729167\n",
            "Epoch: 38   Train loss: 0.196581   Test loss: 0.850861   Train accuracy 0.930556   Test accuracy is 0.725694\n",
            "Epoch: 39   Train loss: 0.078208   Test loss: 0.776344   Train accuracy 0.986111   Test accuracy is 0.718750\n",
            "Epoch: 40   Train loss: 0.119478   Test loss: 0.875562   Train accuracy 0.972222   Test accuracy is 0.701389\n",
            "Epoch: 41   Train loss: 0.076963   Test loss: 0.973098   Train accuracy 1.000000   Test accuracy is 0.680556\n",
            "Epoch: 42   Train loss: 0.153228   Test loss: 0.916519   Train accuracy 0.958333   Test accuracy is 0.694444\n",
            "Epoch: 43   Train loss: 0.081156   Test loss: 1.029596   Train accuracy 0.986111   Test accuracy is 0.663194\n",
            "Epoch: 44   Train loss: 0.231956   Test loss: 2.255782   Train accuracy 0.875000   Test accuracy is 0.510417\n",
            "Epoch: 45   Train loss: 0.135939   Test loss: 1.012131   Train accuracy 0.944444   Test accuracy is 0.659722\n",
            "Epoch: 46   Train loss: 0.160361   Test loss: 0.938994   Train accuracy 0.930556   Test accuracy is 0.697917\n",
            "Epoch: 47   Train loss: 0.186628   Test loss: 0.831450   Train accuracy 0.930556   Test accuracy is 0.715278\n",
            "Epoch: 48   Train loss: 0.171371   Test loss: 0.927716   Train accuracy 0.944444   Test accuracy is 0.677083\n",
            "Epoch: 49   Train loss: 0.153020   Test loss: 0.979548   Train accuracy 0.958333   Test accuracy is 0.687500\n",
            "The average accuracy is: 0.6297222222222222\n",
            "The best accuracy is: 0.7291666666666666\n",
            "subject 1 duration: 0:09:27.605374\n",
            "Fri Apr 19 10:29:11 2024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_VYAdLB9YS0l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}